{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from top2vec import Top2Vec\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DATASET = \"sample50k_health_tech\"\n",
    "\n",
    "SUBSAMPLE_PATH = Path(\"../data/subsamples\")\n",
    "MODEL_PATH = Path(\"../results/models\")/DATASET\n",
    "TOPIC_PATH = Path(\"../results/topics\")\n",
    "MODEL_PATH.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of articles: 29360\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\n",
    "  f\"{SUBSAMPLE_PATH}/{DATASET}.csv\",\n",
    "  usecols = (0,4)\n",
    "  )\n",
    "df.columns = [\"article_id\", \"article\"]\n",
    "df = df.dropna(subset=['article'])\n",
    "\n",
    "print(f\"number of articles: {df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Top2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-15 15:40:09,097 - top2vec - INFO - Pre-processing documents for training\n",
      "c:\\Users\\angel\\miniconda3\\envs\\fourthbrain-glg\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "2022-05-15 15:41:40,752 - top2vec - INFO - Downloading universal-sentence-encoder model\n",
      "2022-05-15 15:41:58,549 - top2vec - INFO - Creating joint document/word embedding\n",
      "INFO:top2vec:Creating joint document/word embedding\n",
      "2022-05-15 15:45:15,561 - top2vec - INFO - Creating lower dimension embedding of documents\n",
      "INFO:top2vec:Creating lower dimension embedding of documents\n",
      "2022-05-15 15:45:54,760 - top2vec - INFO - Finding dense areas of documents\n",
      "INFO:top2vec:Finding dense areas of documents\n",
      "2022-05-15 15:46:00,824 - top2vec - INFO - Finding topics\n",
      "INFO:top2vec:Finding topics\n"
     ]
    }
   ],
   "source": [
    "embedding_module = 'universal-sentence-encoder'\n",
    "speed = 'learn'\n",
    "\n",
    "model = Top2Vec(documents=df.article.values,  embedding_model=embedding_module, speed=speed, workers=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model artifacts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(f\"{MODEL_PATH}/top2vec_{embedding_module}_{speed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create model hierarchy and save as json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group topics: returns list of lists storing subtopics\n",
    "\n",
    "NUM_TOPICS_LVL1 = 20\n",
    "\n",
    "model = Top2Vec.load(f\"{MODEL_PATH}/top2vec_{embedding_module}_{speed}\")\n",
    "hierarchy = model.hierarchical_topic_reduction(NUM_TOPICS_LVL1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create csv file to review and hand label level 1 topics \n",
    "# Updated hierarchy dict with handlabelled topics descriptions\n",
    "\n",
    "NUM_TOPICS_LVS2 = model.get_num_topics()\n",
    "topic_words, word_scores, topic_nums = model.get_topics(NUM_TOPICS_LVS2)\n",
    "\n",
    "topic_list = []\n",
    "for i, h in enumerate(hierarchy):\n",
    "    # match level 1 topic to level 2 topic (i.e. subtopic)\n",
    "    topic_levels = list(zip([i] * len(h), h))\n",
    "    topic_list.extend(topic_levels)\n",
    "\n",
    "topic_list = sorted(topic_list, key=lambda x: x[1]) # could remove this..\n",
    "topic_list = pd.DataFrame(topic_list, columns = [\"topic_level1\", \"topic_level2\"])\n",
    "topic_list.loc[topic_list.index, \"topic_words_level2\"] = pd.Series(list(topic_words))\n",
    "topic_list.loc[topic_list.index, \"word_scores_level2\"] = pd.Series(list(word_scores))\n",
    "topic_list = topic_list.set_index(\"topic_level2\")\n",
    "\n",
    "all_topics = pd.DataFrame(topic_words)\n",
    "all_topics = all_topics.merge(topic_list, left_index=True, right_index=True)\n",
    "all_topics.to_csv(f\"{TOPIC_PATH}/{DATASET}_top2vec.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get hand labelled topics and save to json file\n",
    "\n",
    "topics_final = pd.read_csv(f\"{TOPIC_PATH}/{DATASET}_top2vec_hand_labelled.csv\")\n",
    "topics_final = topics_final[['main_topic', 'topic_level1_descr','topic_level1', 'topic_level2']]\n",
    "topics_final = topics_final.set_index(\"topic_level2\")\n",
    "topics_final = topics_final.merge(topic_list[[\"topic_words_level2\", \"word_scores_level2\"]], left_index=True, right_index=True)\n",
    "topics_final.to_json(f\"{TOPIC_PATH}/{DATASET}_top2vec.json\", orient='index')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "feb9fbdaf8823060a978ec464cb9b002124d7b95a0c8d909409fa113c0eca975"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('fourthbrain-glg')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
