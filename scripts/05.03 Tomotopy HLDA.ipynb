{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tomotopy as tp\n",
    "from pathlib import Path\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from spacy.lang.en.stop_words import STOP_WORDS as en_stop\n",
    "\n",
    "# import spacy\n",
    "# nltk.download('omw-1.4')\n",
    "# nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avx2\n"
     ]
    }
   ],
   "source": [
    "print(tp.isa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add redundant words to stop words\n",
    "en_stop.add(\"said\")\n",
    "en_stop.add(\"reuters\")\n",
    "en_stop.add(\"london\")\n",
    "en_stop.add(\"new york\")\n",
    "en_stop.add('reuters')\n",
    "en_stop.add('say')\n",
    "en_stop.add('like')\n",
    "en_stop.add('thing')\n",
    "en_stop.add('york')\n",
    "en_stop.add('new')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = Path(\"../results/models/tomotopy\")\n",
    "MODEL0 = \"test-hlda0.tmm\"\n",
    "MODEL1 = \"test-hlda1.tmm\"\n",
    "MODEL2 = \"test-hlda2.tmm\"\n",
    "MODEL3 = \"test-hlda3.tmm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load from file\n",
    "mdl0 = tp.HLDAModel.load(f\"{MODEL_PATH}/{MODEL0}\")\n",
    "mdl1 = tp.HLDAModel.load(f\"{MODEL_PATH}/{MODEL1}\")\n",
    "mdl2 = tp.HLDAModel.load(f\"{MODEL_PATH}/{MODEL2}\")\n",
    "mdl3 = tp.HLDAModel.load(f\"{MODEL_PATH}/{MODEL3}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_names = {#name the clusters as seems reasonable\n",
    "    0: \"Science and Technology\",#tech and business\n",
    "    1: \"Health/Science/Drugs\",#health\n",
    "    2: \"Business/Tech/BioTech\",#business\n",
    "    3: \"Entertainment/News\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(unseen_doc):\n",
    "    \"\"\"\n",
    "    Preprocesses text and returns tomotopy corups.\n",
    "    \n",
    "    unseen_doc: str\n",
    "    \"\"\"\n",
    "\n",
    "    lemmatizer = WordNetLemmatizer()  \n",
    "    pat = re.compile('\\w+')\n",
    "\n",
    "    corpus = tp.utils.Corpus(\n",
    "            tokenizer = tp.utils.SimpleTokenizer(stemmer=None, lowercase=True), \n",
    "            stopwords = lambda x: len(x) <= 2 or x in en_stop or x.isnumeric() or not pat.match(x) or not lemmatizer.lemmatize(x)\n",
    "        )\n",
    "\n",
    "    corpus.process(document.lower() for document in unseen_doc)\n",
    "    return corpus\n",
    "\n",
    "\n",
    "def get_best_model(list_of_models, document_text):\n",
    "    \"\"\"\n",
    "    Takes list of HLDAModels and string of article text.\n",
    "    Returns best HLDAModel and topic distribution of \n",
    "    document_text.\n",
    "    \"\"\"\n",
    "\n",
    "    corpus = process_text(document_text)\n",
    "\n",
    "    mdl_results=[]\n",
    "    for mdl in list_of_models:\n",
    "        topic_dist, ll = mdl.infer(corpus)\n",
    "        mdl_results.append((topic_dist, ll))\n",
    "\n",
    "    max_ll = max(mdl_results, key=lambda item: item[1])[1]\n",
    "    max_topic_dist = max(mdl_results,key=lambda item: item[1])[0]\n",
    "    max_index = mdl_results.index((max_topic_dist, max_ll))\n",
    "    mdl_final = mdls[max_index]\n",
    "\n",
    "    return mdl_final, max_topic_dist[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bitcoin continued to slide after a broader stock sell-off in the U.S. last week sent the cryptocurrency market into a frenzy and prompted bitcoin to plummet by roughly 10%. Bitcoin, the world’s largest digital currency by market value, was lower by about 3% at $33,438.03 late Sunday, according to data from Coin Metrics. This year, Bitcoin has been trading in a narrow range as it attempts to reclaim its highs of late 2021. The cryptocurrency is now down 50% from its peak price of $67,802.30 in November 2021. The drop comes after the blue-chip Dow Jones Industrial Average lost more than 1,000 points on Thursday and the Nasdaq plunged by 5%. Those losses marked the worst single-day drops since 2020. The Dow and Nasdaq fell again on Friday.']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample text\n",
    "other_texts = {'txt':['Bitcoin continued to slide after a broader stock sell-off in the U.S. last week sent the cryptocurrency market into a frenzy and prompted bitcoin to plummet by roughly 10%. Bitcoin, the world’s largest digital currency by market value, was lower by about 3% at $33,438.03 late Sunday, according to data from Coin Metrics. This year, Bitcoin has been trading in a narrow range as it attempts to reclaim its highs of late 2021. The cryptocurrency is now down 50% from its peak price of $67,802.30 in November 2021. The drop comes after the blue-chip Dow Jones Industrial Average lost more than 1,000 points on Thursday and the Nasdaq plunged by 5%. Those losses marked the worst single-day drops since 2020. The Dow and Nasdaq fell again on Friday.']}\n",
    "unseen = other_texts['txt']\n",
    "unseen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tomotopy.HLDAModel at 0x16a58e9ec30>, array([  0,  13, 161]))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdls = [mdl0, mdl1 ,mdl2, mdl3]\n",
    "final_model, topic_dist = get_best_model(mdls, unseen)\n",
    "final_model, topic_dist.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model depth: 3\n",
      "number of topic: 264\n"
     ]
    }
   ],
   "source": [
    "print(f\"model depth: {final_model.depth}\")\n",
    "print(f\"number of topic: {final_model.k}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to get topic tree.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# topic_levels = [final_model.level(k) for k in range(final_model.k)] # list of all topic level\n",
    "topic_levels = [k for k in range(final_model.k) if final_model.level(k) == 1] # list of the model's level 1 topics\n",
    "len(topic_levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 64,\n",
       " 65,\n",
       " 66,\n",
       " 67,\n",
       " 68,\n",
       " 69,\n",
       " 70,\n",
       " 71,\n",
       " 96,\n",
       " 97,\n",
       " 98,\n",
       " 99,\n",
       " 100,\n",
       " 101,\n",
       " 102,\n",
       " 103,\n",
       " 128,\n",
       " 129,\n",
       " 130,\n",
       " 131,\n",
       " 132,\n",
       " 133,\n",
       " 134,\n",
       " 135,\n",
       " 176,\n",
       " 177,\n",
       " 178,\n",
       " 179,\n",
       " 180,\n",
       " 181,\n",
       " 182,\n",
       " 183]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for doc in max_cps:\n",
    "#     for path in doc.path:\n",
    "#       if path==0:\n",
    "#         print('Root Topic is {}'.format(cluster_names.get(max_index)))\n",
    "#         print('Subtopics Level {}:\\n{}'.format(path,[i[0] for i in mdl_final.get_topic_words(path)]))\n",
    "#       else:\n",
    "#         print('Subtopics Level {}:\\n{}'.format(path,[i[0] for i in mdl_final.get_topic_words(path)]))\n",
    "#     print('Original Unseen Word|Probability pairs:\\n{}'.format(doc.get_words(top_n=10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   9 479]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for doc in max_cps:\n",
    "    print(doc.path)\n",
    "    i += 1\n",
    "\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl1.depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([182, 180, 183, 178, 181, 179, 177, 176, 135, 132, 130, 134, 133,\n",
       "       131, 129, 128, 103, 102, 101, 100,  99,  98,  97,  96,  71,  70,\n",
       "        69,  68,  67,  66,  65,  64,  39,  38,  37,  36,  35,  34,  33,\n",
       "        32,  15,  14,  13,  12,  11,  10,   9,   8], dtype=uint32)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl2.children_topics(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([115,  56, 161, 110, 107,  78,  25,  24], dtype=uint32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl2.children_topics(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=uint32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl2.children_topics(161)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=uint32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl2.children_topics(161)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl0.parent_topic(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl0.level(161)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl0.parent_topic(44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('health', 6.353240314638242e-05),\n",
       " ('people', 6.353240314638242e-05),\n",
       " ('percent', 6.353240314638242e-05),\n",
       " ('year', 6.353240314638242e-05),\n",
       " ('study', 6.353240314638242e-05),\n",
       " ('according', 6.353240314638242e-05),\n",
       " ('drug', 6.353240314638242e-05),\n",
       " ('trump', 6.353240314638242e-05),\n",
       " ('years', 6.353240314638242e-05),\n",
       " ('care', 6.353240314638242e-05)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl1.get_topic_words(1) # mld0 has 568 topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('company', 0.06128843128681183),\n",
       " ('coverage', 0.04730544611811638),\n",
       " ('text', 0.04590891674160957),\n",
       " ('source', 0.04582052677869797),\n",
       " ('eikon', 0.032615356147289276),\n",
       " ('newsroom', 0.029698552563786507),\n",
       " ('gdynia', 0.024713467806577682),\n",
       " ('says', 0.016192862764000893),\n",
       " ('million', 0.011826494708657265),\n",
       " ('agreement', 0.01037693116813898)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl2.get_topic_words(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "feb9fbdaf8823060a978ec464cb9b002124d7b95a0c8d909409fa113c0eca975"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('fourthbrain-glg')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
