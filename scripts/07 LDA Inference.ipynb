{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = \"sample50k_health_tech\"\n",
    "MODEL_NAME = \"lda_50i4p24t\"\n",
    "DICTIONARY_PATH = Path(\"../results/dictionary\")\n",
    "MODEL_PATH = Path(\"../results/models\")/DATASET\n",
    "PROCESSED_PATH = Path(\"../data/data_processed\")\n",
    "INFERENCE_PATH = (Path(\"../results/inference\")/DATASET)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load saved dictionary and corpus\n",
    "dictionary = corpora.Dictionary.load(f\"{DICTIONARY_PATH/DATASET}\")\n",
    "lda = LdaModel.load(f\"{MODEL_PATH}/{MODEL_NAME}.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_articles = list((PROCESSED_PATH/DATASET).iterdir())\n",
    "\n",
    "class MyCorpusInference(object):\n",
    "    def __iter__(self):\n",
    "        for line in open(file_t):\n",
    "            yield json.loads(line)[\"article_id\"], lda[dictionary.doc2bow(json.loads(line)[\"article\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_pred = []\n",
    "\n",
    "for c, file_t in enumerate(tokenized_articles):\n",
    "    inference_corpus_memory_friendly = MyCorpusInference()\n",
    "    topics_inferred = [\n",
    "        (id, vector)\n",
    "        for id, vector in inference_corpus_memory_friendly\n",
    "        ]\n",
    "    topics_pred.extend(topics_inferred)\n",
    "\n",
    "\n",
    "article_topics = pd.DataFrame(topics_pred, columns= [\"article_id\", \"topic_list\"])\n",
    "article_topics[\"num_topics\"] = article_topics[\"topic_list\"].apply(lambda x: len(x))\n",
    "article_topics[[\"main_topic\", \"main_topic_proba\"]] = article_topics[\"topic_list\"].apply(lambda x: sorted(x, key=lambda item: item[1])[-1]).apply(pd.Series)\n",
    "article_topics[\"main_topic\"] = article_topics[\"main_topic\"].astype(int)\n",
    "\n",
    "article_topics.to_csv(f\"{INFERENCE_PATH}/{MODEL_NAME}.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>topic_list</th>\n",
       "      <th>num_topics</th>\n",
       "      <th>main_topic</th>\n",
       "      <th>main_topic_proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>901965</td>\n",
       "      <td>[(14, 0.5309663), (15, 0.1799154), (16, 0.1225...</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>0.530966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1360482</td>\n",
       "      <td>[(0, 0.12812088), (3, 0.09798139), (10, 0.6530...</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.653085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2557016</td>\n",
       "      <td>[(0, 0.017679628), (1, 0.05004615), (3, 0.0709...</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>0.534344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>592207</td>\n",
       "      <td>[(7, 0.9895776)]</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.989578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>571034</td>\n",
       "      <td>[(3, 0.017763685), (7, 0.43124837), (11, 0.075...</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0.431248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id                                         topic_list  num_topics  \\\n",
       "0      901965  [(14, 0.5309663), (15, 0.1799154), (16, 0.1225...           4   \n",
       "1     1360482  [(0, 0.12812088), (3, 0.09798139), (10, 0.6530...           5   \n",
       "2     2557016  [(0, 0.017679628), (1, 0.05004615), (3, 0.0709...           7   \n",
       "3      592207                                   [(7, 0.9895776)]           1   \n",
       "4      571034  [(3, 0.017763685), (7, 0.43124837), (11, 0.075...           5   \n",
       "\n",
       "   main_topic  main_topic_proba  \n",
       "0          14          0.530966  \n",
       "1          10          0.653085  \n",
       "2          10          0.534344  \n",
       "3           7          0.989578  \n",
       "4           7          0.431248  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_topics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.010420279),\n",
       " (1, 0.010420279),\n",
       " (2, 0.010420279),\n",
       " (3, 0.010420279),\n",
       " (4, 0.010420279),\n",
       " (5, 0.010420279),\n",
       " (6, 0.010420279),\n",
       " (7, 0.010420279),\n",
       " (8, 0.010420279),\n",
       " (9, 0.010420279),\n",
       " (10, 0.010420279),\n",
       " (11, 0.48621953),\n",
       " (12, 0.010420279),\n",
       " (13, 0.010420279),\n",
       " (14, 0.010420279),\n",
       " (15, 0.010420279),\n",
       " (16, 0.010420279),\n",
       " (17, 0.010420279),\n",
       " (18, 0.010420279),\n",
       " (19, 0.010420279),\n",
       " (20, 0.28453434),\n",
       " (21, 0.010420279),\n",
       " (22, 0.010420279),\n",
       " (23, 0.010420279)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unseen_doc = dictionary.doc2bow([\"medicine\", \"desease\", \"forest\", \"hospital\"])\n",
    "lda[unseen_doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1,\n",
       "  '0.033*\"facebook\" + 0.014*\"company\" + 0.012*\"user\" + 0.011*\"social\" + 0.011*\"twitter\" + 0.010*\"people\" + 0.010*\"medium\" + 0.009*\"post\" + 0.008*\"video\" + 0.008*\"mr\"'),\n",
       " (15,\n",
       "  '0.032*\"study\" + 0.014*\"research\" + 0.012*\"researcher\" + 0.011*\"woman\" + 0.009*\"find\" + 0.009*\"disease\" + 0.009*\"risk\" + 0.009*\"dr\" + 0.009*\"new\" + 0.008*\"brain\"'),\n",
       " (12,\n",
       "  '0.035*\"china\" + 0.024*\"chinese\" + 0.018*\"united\" + 0.016*\"states\" + 0.016*\"country\" + 0.016*\"huawei\" + 0.015*\"government\" + 0.013*\"company\" + 0.011*\"world\" + 0.010*\"american\"'),\n",
       " (18,\n",
       "  '0.025*\"health\" + 0.018*\"care\" + 0.011*\"people\" + 0.010*\"program\" + 0.010*\"year\" + 0.009*\"state\" + 0.008*\"plan\" + 0.006*\"service\" + 0.006*\"insurance\" + 0.006*\"pay\"'),\n",
       " (19,\n",
       "  '0.035*\"cancer\" + 0.020*\"school\" + 0.015*\"student\" + 0.014*\"study\" + 0.014*\"death\" + 0.013*\"year\" + 0.012*\"rate\" + 0.012*\"report\" + 0.011*\"high\" + 0.010*\"increase\"'),\n",
       " (9,\n",
       "  '0.038*\"company\" + 0.024*\"mr\" + 0.013*\"uber\" + 0.011*\"year\" + 0.010*\"business\" + 0.010*\"new\" + 0.009*\"billion\" + 0.008*\"tech\" + 0.008*\"google\" + 0.008*\"executive\"'),\n",
       " (3,\n",
       "  '0.018*\"car\" + 0.012*\"space\" + 0.008*\"year\" + 0.008*\"vehicle\" + 0.007*\"city\" + 0.006*\"new\" + 0.006*\"air\" + 0.005*\"driver\" + 0.005*\"test\" + 0.005*\"drone\"'),\n",
       " (22,\n",
       "  '0.055*\"drug\" + 0.027*\"company\" + 0.026*\"fda\" + 0.012*\"product\" + 0.011*\"price\" + 0.011*\"patient\" + 0.009*\"trial\" + 0.009*\"market\" + 0.008*\"approve\" + 0.008*\"johnson\"'),\n",
       " (14,\n",
       "  '0.031*\"food\" + 0.018*\"eat\" + 0.012*\"ecigarette\" + 0.012*\"drink\" + 0.011*\"product\" + 0.010*\"vape\" + 0.009*\"diet\" + 0.008*\"health\" + 0.008*\"tobacco\" + 0.007*\"flavor\"'),\n",
       " (5,\n",
       "  '0.037*\"article\" + 0.022*\"email\" + 0.020*\"misstate\" + 0.017*\"error\" + 0.015*\"comment\" + 0.009*\"correction\" + 0.009*\"sunday\" + 0.008*\"incorrectly\" + 0.008*\"new\" + 0.008*\"refer\"')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lda.show_topics(formatted=False)\n",
    "lda.show_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "feb9fbdaf8823060a978ec464cb9b002124d7b95a0c8d909409fa113c0eca975"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('fourthbrain-glg')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
